{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# llamafile setup\n",
    "\n",
    "# Step 1: Download a llamafile. The download may take several minutes.\n",
    "# wget https://huggingface.co/Mozilla/Meta-Llama-3.1-8B-Instruct-llamafile/resolve/main/Meta-Llama-3.1-8B-Instruct.Q6_K.llamafile\n",
    "\n",
    "# Step 2: Make the llamafile executable. Note: if you're on Windows, just append '.exe' to the filename.\n",
    "# chmod +x Meta-Llama-3.1-8B-Instruct.Q6_K.llamafile\n",
    "\n",
    "# Step 3: Start llamafile server in background. All the server logs will be written to 'tinyllama.log'.\n",
    "# Alternatively, you can just open a separate terminal outside this notebook and run: \n",
    "#   ./Meta-Llama-3.1-8B-Instruct.Q6_K.llamafile --server --nobrowser --embedding\n",
    "# ./Meta-Llama-3.1-8B-Instruct.Q6_K.llamafile --server --nobrowser --embedding > tinyllama.log 2>&1 &\n",
    "./TinyLlama-1.1B-Chat-v1.0.Q5_K_M.llamafile --server --nobrowser --embedding > tinyllama.log 2>&1 &\n",
    "pid=$!\n",
    "echo \"${pid}\" > .llamafile_pid  # write the process pid to a file so we can terminate the server later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gerson/Projects/Magalu/vector-store/venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "from time import perf_counter\n",
    "import lancedb\n",
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "from langchain_community.vectorstores import LanceDB\n",
    "\n",
    "from langchain_community.embeddings import LlamafileEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_community.llms.llamafile import Llamafile\n",
    "from utils.text import get_pdf_text, get_text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = \"lance\"\n",
    "statistics = [f\"save_{experiment}\", f\"search_{experiment}\", f\"execute_{experiment}\"]\n",
    "dict_json = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = LlamafileEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Llamafile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = get_text_chunks(get_pdf_text(\"resume.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = \"minioadmin\"\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = \"minioadmin\"\n",
    "os.environ[\"AWS_ENDPOINT\"] = \"http://localhost:9000\"\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = \"us-east-1\"\n",
    "os.environ[\"ALLOW_HTTP\"] = \"true\"\n",
    "minio_bucket_name = \"lance\"\n",
    "\n",
    "# Create a boto3 session with path-style access\n",
    "session = boto3.Session()\n",
    "s3_client = session.client(\"s3\", config=botocore.config.Config(s3={'addressing_style': 'path'}))\n",
    "\n",
    "# Connect to LanceDB using path-style URI and s3_client\n",
    "db_uri = f\"s3://{minio_bucket_name}/tables\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = lancedb.connect(db_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-01T19:37:49Z WARN  lance_table::io::commit] Using unsafe commit handler. Concurrent writes may result in data loss. Consider providing a commit handler that prevents conflicting writes.\n"
     ]
    }
   ],
   "source": [
    "time_start = perf_counter()\n",
    "vectorstore = LanceDB.from_documents(documents=docs, embedding=embedder, connection=db)\n",
    "time_duration = perf_counter() - time_start\n",
    "dict_json.setdefault(experiment, {})[\"save\"] = time_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'page': 0, 'source': 'resume.pdf'}, page_content='DataOrchestrationandDataOpsEngineeringTemplate(03/2023-Present)-Developedanopen-sourcerepositoryandprojectprovidingacomprehensiveframeworkandasuiteoftoolsforDataOrchestrationandDataOps.-Designedtosimplifytheend-to-endmanagementofdataworkflows,theprojectincludestoolscapableofperformingdataextraction,transformation,andloading(ETL),datavalidation,andmonitoring.-Aimedatstreamliningdataoperationsandenhancingdatareliability,thetemplatefacilitatesseamlessorchestrationofdatapipelines,ensuringefficientdataflowandtimelyprocessing.-Committedtofosteringacollaborativeandthrivingdatacommunity,theprojectembracesopen-sourceprinciples,enablingdataengineerstoleveragethetemplatefordiversedata-drivenprojectswithease.'), Document(metadata={'page': 0, 'source': 'resume.pdf'}, page_content=\"0 3 / 2 0 1 0-1 2 / 2 0 1 5,8 0 . 5 %Master's,AppliedInformaticsUniversidadeFederalRuraldePernambuc o\\n0 3 / 2 0 1 8-0 2 / 2 0 2 0,H i g h e s tD i s t i n c t i o n-1 0 0 %SKILLS\\nPERSONALPROJECTSGravitationalWaveDetectionusingArtificialNeuralNetworks(02/2019-02/2020)-DevelopedacomputationalprocedurebasedonArtificialNeuralNetworks(ANN)todetectblackhole-blackholegravitationalwaveeventsfromLIGOdata.-Achievedaccurateidentificationwithahigh-scoresystemindicatinggravitationalwaveobservationandlowvaluesindicatingnoise.-ReceivedtopmarksandearnedmaximumscoreduringthethesisdefensepresentationformyMaster'sproject,demonstratingtheefficacyandsignificanceoftheANN-basedapproachindetectinggravitationalwavesignals.-PresentedresearchfindingsinanarticleshowcasingtheeffectivenessoftheANN-basedapproachindetectinggravitationalwavesignals.\"), Document(metadata={'page': 0, 'source': 'resume.pdf'}, page_content=\"-Mentoredandguidedstudentsinacademicprojects,fosteringcriticalthinkingandproblem-solvingskills.\\nSubstituteProfessoratIFPBInstitutoFederaldaParaíba\\n0 5 / 2 0 1 7-0 4 / 2 0 1 8,O n - s i t e\\nA c h i e v e m e n t s / T a s k s,M o t e i r o ,P a r a í b a ,B r a z i l\\n-Conduct edlecturesandpracticalsessionsinvariouscourses,includingAdminis trationofProprietaryandOpenOperatingSystems,IntroductiontoProgrammingandProjectManagement.\\n-Developedanddeliveredengagingteachingmaterials,integratinginnovativetoolslikeScratch,AppInventor,andunpluggedactivitiestoenhancestudentlearningexperiences.-Evaluatedstudentperformanceandprovidedvaluablefeedbacktosupporttheiracademicprogressandfostercontinuousimprovement.\\nEDUCATIONBachelor's,InformationSystemsUniversidadeFederalRuraldePernambuc o\\n0 3 / 2 0 1 0-1 2 / 2 0 1 5,8 0 . 5 %Master's,AppliedInformaticsUniversidadeFederalRuraldePernambuc o\\n0 3 / 2 0 1 8-0 2 / 2 0 2 0,H i g h e s tD i s t i n c t i o n-1 0 0 %SKILLS\"), Document(metadata={'page': 0, 'source': 'resume.pdf'}, page_content='GersonSantos\\nDataScientist|SoftwareDeveloperProficientinPython/MachineLearningbasedmicroservicesdevelopmen tandanabilitytotranslatebusinessrequirementsintotechnicalsolutions.Ihaveapassionforconsistentlearningandinnovating.\\nWORKEXPERIENCEDataScientistatCESARCentrodeEstudoseSistemasAvançadosdoRecife\\n0 2 / 2 0 2 0-P r e s e n t,R e m o t e\\nA c h i e v e m e n t s / T a s k s,R e c i f e ,P e r n a m b u c o ,B r a z i l\\n-WorkinginanR&DteamfocusedresearchinthefieldofSoftwareEngineering ,DataScienceandAIdevelopingsolutionstosolveavarietyofproblemsforaglobalclient;\\n-ResponsiblefordevelopingmicroservicesinPythoninvolvingpipelines,datastreaming(Spark),messagingsystems(Kafka,RabbitMQ )withtechnologiessuchasDocker,Kubernetes,HelmChart,RESTAPI,gRPC,MongoDB,SQL,OracleDB,CI/CD\\n-Planned,trained,evaluated,deployed,andmaintainedMachinelearning /Deeplearningmodelsusingtools/frameworkssuchasPyTorch,Scikit-Learn,Feast,ApacheAirflow,MLflow,Pandas,Numpy;')]\n"
     ]
    }
   ],
   "source": [
    "# query it\n",
    "query = \"What professions did Gerson have?\"\n",
    "time_start = perf_counter()\n",
    "results = vectorstore.similarity_search(query)\n",
    "time_duration = perf_counter() - time_start\n",
    "dict_json.setdefault(experiment, {})[\"search\"] = time_duration\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=vectorstore.as_retriever())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gerson/Projects/Magalu/vector-store/venv/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Gerson is a Data Scientist, Software Developer, and Data Scientist with expertise in Python/Machine Learning, Microservices development, technical solutions for business requirements. He has experience working in an R&D team focused on solving various problems related to software engineering, data science, and AI technologies. He is responsible for developing microservices in Python using various technologies such as Docker, Kubernetes, HelmChart, REST APIs, gRPC, MongoDB, SQL, Oracle DB, CI/CD, Machine Learning/Deep Learning models using tools like PyTorch, Scikit-Learn, Feast, Apache Airflow, and MPLF. He has also worked on building machine learning / deep learning models using Python frameworks such as PyTorch, Scikit-Learn, and Feast.</s>\n"
     ]
    }
   ],
   "source": [
    "query = \"What professions did Gerson have?\"\n",
    "time_start = perf_counter()\n",
    "response = qa.run(query)\n",
    "time_duration = perf_counter() - time_start\n",
    "dict_json.setdefault(experiment, {})[\"execute\"] = time_duration\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# cleanup: kill the llamafile server process\n",
    "kill $(cat .llamafile_pid)\n",
    "rm .llamafile_pid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "with open(f\"results/{experiment}/{timestr}.json\", \"w\") as f:\n",
    "    json.dump(dict_json, f, ensure_ascii=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
